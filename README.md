AI Podcast 自動化處理工具開發歷程報告

專案作者： 王宏業
開發期間： 2025年6月
專案目標： 開發一套能夠自動偵測並移除 Podcast 音訊中廣告片段的 AI 工具鏈。

一、 專案啟發與目標設定

本專案啟發於一個日常需求，Podcast在我的生活中占據了很大一部分，我不論通勤甚至是睡覺都在聽Podcast，在享受 Podcast 內容時，時常被插入的廣告打斷，影響聆聽的連貫性。而Podcast對比傳統的影音平台，如Youtube廣告營利的方式不同，通常都是直接口播而非插入式的廣告。傳統的手動快轉方式效率低下且不精準。因此，本專案設定的核心目標是，利用現行的 AI 技術，打造一個能夠自動化完成「下載 -> 轉譯 -> 分析 -> 剪輯」流程的工具，以產生一個純淨、無廣告的音訊檔案。

專案初期，我們將目標拆解為四個可執行的核心模組：

    Podcast 下載器： 能從 RSS Feed 自動抓取最新的音訊檔案。

    語音轉譯器： 將音訊內容轉換為帶有精確時間戳記的文字稿。

    AI 內容分析器： 利用大型語言模型 (LLM) 讀取文字稿，辨識出廣告片段。

    音訊剪輯器： 根據分析結果，自動移除原始音檔中的廣告部分。

二、 核心技術棧探索與選型

在開發過程中，我們對每個模組的技術選型都進行了深入的探索與比較，最終確定了一套兼具效能、成本與彈性的技術組合。

1. 音訊下載與處理：

    採用 Python 的 requests 函式庫來抓取 RSS Feed，並使用內建的 xml.etree.ElementTree 來解析 XML 內容。

    音訊的剪輯與壓縮，則選擇了強大的 pydub 函式庫，並在系統層面成功配置了其後端依賴 ffmpeg，掌握了使用命令列進行音訊剪輯的核心技能。

2. 語音轉譯 (Speech-to-Text)：

這是專案的技術核心。我們對比了雲端 API 與本地部署兩種路徑：

    雲端 API 探索：

        OpenAI Whisper API： 作為初期測試的基準，其高品質的轉錄結果和極具競爭力的價格 ($0.006/分鐘)。

        Groq API： 其 LPU 晶片帶來的極致轉錄速度，但其API目前不提供精確時間戳記，不適用於後續的剪輯任務。

    本地部署方案 (最終選定)：

        目標： 在低功耗的 ARM 開發板 Radxa Zero 3W 上實現免費、私密的本地轉錄。

        挑戰： 該裝置無 NVIDIA GPU，無法使用標準的 PyTorch CUDA 加速。

        最終解決方案： 成功選擇、編譯並部署了 C++ 版本的 whisper.cpp。它憑藉超高效能和低資源佔用的特性，讓在 Radxa 上流暢地進行本地轉錄成為可能，是整個專案的重大技術突破。

3. AI 內容分析 (LLM)：

    API 供應商探索：

        OpenRouter： 作為一個「模型超級市場」，讓我們能夠靈活測試來自不同公司的模型，如 Google 的 Gemma 和 Anthropic 的 Claude。

        Google AI Studio (最終選定)： 為了追求更穩定、更慷慨的免費額度，最終選擇直接對接 Google 的原生 API。

    模型選擇： 在測試了 Gemma、Gemini Flash 等模型後，最終選定 gemini-2.0-flash 作為主力分析模型，因其強大的長文本理解能力(context length < 1M)和遵循複雜指令的穩定性。

三、 開發環境與專業實踐

除了核心功能，本專案也注重建立一個專業、穩健的開發環境。

    虛擬環境 (venv)： 從專案初期便堅持使用，為專案的 Python 依賴提供了一個乾淨、隔離的獨立環境，避免了版本衝突。

    版本控制 (git)： 建立了全面的 .gitignore 檔案來排除不必要的檔案（如 venv, node_modules, .env），並學習了使用 git branch 來進行新功能的安全開發與實驗。

    系統與命令列 (CLI)：

        成功在 Windows 和 Linux (Radxa) 兩種不同作業系統上配置了 ffmpeg 的環境變數。

        掌握了在 Linux 環境下使用 make, cmake 和 g++ 從原始碼編譯 C++ 專案 (whisper.cpp)，並學會了使用 -j 參數進行並行編譯以提升效率。

        熟練掌握了處理含有空格或特殊字元檔案路徑的技巧（使用引號或 Tab 補全）。

四、 核心挑戰與解決方案

開發過程中遇到的挑戰是學習最深刻的部分。

    挑戰：API 限制與錯誤處理

        問題： 遇到 OpenAI 的 25MB 檔案大小限制。

        解決方案： 開發了「智慧壓縮」腳本 (smart_compressor.py)，能自動計算所需位元速率將檔案壓縮至目標大小。

    挑戰：本地部署的環境障礙

        問題： 在 Radxa 上編譯 whisper.cpp 時，遇到了缺少 cmake 依賴、執行檔路徑變更、main 指令被棄用等問題。

        解決方案： 透過仔細閱讀錯誤訊息，逐一使用 sudo apt install 安裝依賴，並根據開發者提示更新執行指令 (main -> whisper-cli)，最終成功完成部署。

    挑戰：異構數據格式的解析

        問題： 發現 whisper.cpp 產生的 JSON 逐字稿格式與 OpenAI API 的格式完全不同，導致後續的分析腳本出錯 (TypeError: string indices must be integers, not 'str')。

        解決方案： 透過實際打印並分析 whisper.cpp 的 JSON 輸出，重寫了 Python 中的解析邏輯，使其能夠精準地從新的資料結構中提取 transcription 列表、offsets 時間戳和 text 內容。

    挑戰：確保 LLM 穩定輸出 JSON

        問題： AI 模型有時會「過於熱心」，在回覆的 JSON 前後加入額外的對話文字，導致程式解析失敗。

        解決方案： 建立了「三層防禦體系」。第一層，在 API 呼叫時啟用「JSON 模式」；第二層，透過提供清晰範例和嚴厲警告來強化 Prompt；第三層，在 Python 程式碼中加入「防禦性解析」邏輯，在解析前先對 AI 回傳的字串進行清理。

    挑戰：本地部署Whisper.cpp效率不佳

        問題： 由於本地部屬的硬體只是簡單的SBC(single board computer)，無GPU加速語音轉換，所以提取時間比時間比RTF(總處理時間 / 音檔實際長度)超過1，如果換用更小的whisper模型(base -> tiny)，提取出來的文字品質又不佳。

        解決方案： 因為目前手上只有一份硬體，但是日後有機會可以使用多塊SBC組合的compute cluster，先將音檔切分，再分別運算提取，由於切分幾乎沒有時間成本，所以日後的發展還是很豐富。

五、 專案成果

本專案最終成功打造了一套由多個獨立、可互動的 Python 腳本組成的自動化工具鏈，實現了從音訊下載到無廣告版本產出的完整流程。

1. rss_downloader_pro.py (自動化下載器)

    作為整個自動化流程的起點，負責從網路上獲取音訊「原料」。

    腳本提供互動式介面，要求使用者輸入目標 Podcast 的 RSS Feed 網址，並可選擇要下載最新的幾集。它會自動為每個節目建立專屬資料夾，並將下載的 MP3 檔案以「日期 - 標題」的格式命名，方便後續管理。

    使用requests 函式庫發送網路請求以獲取 RSS Feed 的 XML 內容，再由 Python 內建的 xml.etree.ElementTree 函式庫進行解析，精準提取出每一集的標題、發布日期和最重要的 MP3 下載連結。

2. run_whisper_cpp.py (高效能本地轉錄器)

    將音訊轉換為帶有時間戳記的結構化文字，是連接聲音與文字世界的橋樑，也是整個專案成本控制和隱私保護的關鍵。

    此腳本封裝了對本地whisper.cpp 引擎的呼叫。它同樣提供互動式選單，讓使用者選擇要處理的檔案和欲使用的模型大小（如tiny, base, small）。它會自動建構正確的命令列指令，並特別加入-oj 參數，指示whisper.cpp 輸出一份包含每一段話精確起訖時間的.json 檔案，這份檔案是後續 AI 分析和剪輯的基礎。

    利用 Python 的 subprocess 模組，來執行外部編譯好的 C++ 程式 (whisper-cli)，實現了 Python 與高效能本地 AI 引擎的完美整合。

3. analyzer_google_api.py (智慧內容分析器)

    扮演專案的「大腦」，負責「理解」逐字稿內容，並找出廣告與內容重點。

    腳本會讀取whisper.cpp 產生的.json 逐字稿，將其格式化為一個清晰、易於理解的字串，然後嵌入一個經過精心設計的 Prompt 中。這個 Prompt 不僅要求 AI (Google Gemini 1.5 Pro) 找出廣告時段，更進一步要求其生成一份內容大綱。為了確保結果的穩定性，Prompt 中包含了清晰的 JSON 輸出格式範例與嚴格的指令。腳本在收到 AI 回應後，還會進行「防禦性解析」，以應對 AI 可能回傳的非標準格式，最終將包含廣告與大綱的完整分析結果儲存為.analysis.json 檔案。

    使用google-generativeai SDK 與 Google Gemini API 進行通訊，並運用了「提示工程 (Prompt Engineering)」的核心技巧來引導大型語言模型完成複雜的雙重任務。

4. audio_splicer.py (精準音訊剪輯器)

    作為流程的最後一站，負責產出最終的「純淨版」產品。

    此腳本會自動尋找那些已經被分析過的集數（即同時擁有.mp3 和.analysis.json 檔案）。它會讀取分析檔案中的ads 列表，並根據其中的時間戳記，計算出所有「非廣告」的內容片段。接著，它會像外科手術一樣，將這些內容片段一一提取出來，再無縫地拼接在一起，最終匯出一個檔名以.ad_free.mp3 結尾的、乾淨流暢的無廣告音訊檔案。

    深度利用pydub 函式庫進行音訊處理，包括以毫秒為單位的精準切片 (slicing)、多個音訊片段的疊加 (sum) 以及最終的 MP3 檔案匯出 (export)。

六、 學習心得與展望

透過這次的自主學習，我不僅實現了最初的設想，更在過程中獲得了成長。在開發的途中AI的協助是必不可少的，同時我也實現了software 3.0，使用自然語言操控LLM幫我執行任務，我不再僅僅是呼叫 API，而是深入到了從系統環境配置、C++ 專案編譯、硬體性能評估，到與大型語言模型進行「溝通」和「博弈」的完整開發鏈條。

世代
	

關鍵特色
	

開發者主要產出
	

典型工具

1.0
	

傳統手寫程式邏輯
	

逐行程式碼（if/for/while…）
	

C/C++、Java、Python…

2.0
	

以資料取代顯式邏輯，由模型自學規則
	

標註資料集 + 模型權重
	

TensorFlow、PyTorch…

3.0
	

以自然語言提示（prompt）＋工具調用作為程式，代理人可自行規劃、驗證、迭代
	

高層次目標說明、系統／任務提示、工具規格
	

LLM（GPT-4o、Llama 3.1…）、LangChain/LangGraph、Autogen、CrewAI 等

然而，在驗證可行性之後，我們也清晰地看到了兩個主要的優化方向，這將是專案從「可用工具」邁向「成熟產品」的關鍵：
首先，在操作環境的友善度方面，目前系統由一系列獨立的 Python 命令列腳本所組成，使用者需具備一定的技術背景，並在終端機中手動依序執行。未來的目標是開發一個統一的圖形化使用者介面（GUI），例如透過 Tauri 和 React 技術打造一個跨平台的桌面應用程式。這個 GUI 將提供一個整合式的儀表板，讓使用者只需透過點擊按鈕，就能輕鬆完成選擇節目、啟動任務、監控進度與管理檔案等所有操作，從而極大地降低使用門檻。

其次，在語音轉譯的效能與彈性方面，目前在 Radxa Zero 3W 上運行的本地 whisper.cpp 方案，雖然實現了免費與隱私保護，但其處理時間與音訊長度成正比，面對長篇 Podcast 時仍需耗費大量時間。因此，未來的優化方向是建立一個混合式處理架構。在此架構下，使用者可以根據自身需求（例如「我需要立即得到結果」或「我可以等待但不想付費」），彈性選擇使用快速的雲端轉譯 API（如 OpenAI Whisper）或免費的本地轉錄引擎，除了雲端方案外也可以在本地轉錄的基礎上做優化(搭建compute cluster)。這種設計讓使用者能在「時間成本」與「金錢成本」之間做出最有利的權衡，使整個工具更具實用性與適應性。
